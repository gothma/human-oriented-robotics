function C = classifynaivebayes(trainingdata,testdata)
% trainingdata and testdata are matrices with one training sample per row,
% one column per feature, and the class label (-1 / +1) in the last column.

% Initialization
class1label =  1;
class2label = -1;
tp = 0; fp = 0;
fn = 0; tn = 0;

% ----- Learn classifier: estimate feature distribution parameters
meantrainingdata = [mean(trainingdata(trainingdata(:,end) > 0)); ...
                    mean(trainingdata(trainingdata(:,end) < 0))];
stdtrainingdata = [std(trainingdata(trainingdata(:,end) > 0),1); ...
                    std(trainingdata(trainingdata(:,end) < 0),1)];

priorclass1 = size(trainingdata(trainingdata(:, end) == class1label),1)/...
    size(trainingdata,1)
priorclass2 = size(trainingdata(trainingdata(:, end) == class2label),1)/...
    size(trainingdata,1)


% ------ Apply classifier to testdata: 
n = size(testdata,1);
for i = 1:n,
  
  % Get query point
  q = testdata(i,1:end-1);

  % Inference
  Yclass1 = normpdf(q, meantrainingdata(1,:), stdtrainingdata(1,:));
  Yclass2 = normpdf(q, meantrainingdata(2,:), stdtrainingdata(2,:));
  

  % Determine label of q
  class1 = log(priorclass1) + sum(log(Yclass1));
  class2 = log(priorclass2) + sum(log(Yclass2));
  if (class1 > class2)
      classlabel = class1label;
  else
      classlabel = class2label;
  end

  % Count classification errors
  % (increment tp, fp, fn, tn depending on the classification result)
  groundtruth = testdata(i, end);
  
  if (classlabel == class1label)
      if (classlabel == groundtruth)
          tp = tp + 1;
      else
          fp = fp + 1;
      end
  else
      if (classlabel == groundtruth)
          tn = tn + 1;
      else
          fn = fn + 1;
      end
  end
  
    
  if mod(i,1000) == 0, disp(['- i = ',int2str(i),' of ',int2str(n)]); end;
end;

C = [tp fp; fn tn];

